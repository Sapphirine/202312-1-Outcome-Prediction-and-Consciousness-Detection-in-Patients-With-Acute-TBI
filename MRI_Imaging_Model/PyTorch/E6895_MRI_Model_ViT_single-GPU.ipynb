{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirements + Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Vars\n",
    "GENERATE_MATLAB_DATA = False\n",
    "DATA_PATH = '/home/cyu/workspace/202312-1-Outcome-Prediction-and-Consciousness-Detection-in-Patients-With-Acute-TBI/data/mri_data_pandas.pkl'\n",
    "RESULT_PATH = '/home/cyu/workspace/202312-1-Outcome-Prediction-and-Consciousness-Detection-in-Patients-With-Acute-TBI/data/MRI_Model.keras'\n",
    "CENTERING = True\n",
    "CONDENSED = False\n",
    "INPUT_RESOLUTION = (256, 256, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader, TensorDataset \n",
    "from vit_pytorch.vit_3d import ViT\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Pandas dataframe\n",
    "if GENERATE_MATLAB_DATA:\n",
    "    drive.mount('/content/drive')\n",
    "file_name = DATA_PATH\n",
    "df_loaded = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Process Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_list(mat_file):\n",
    "  \"\"\"\n",
    "  Input: mat_file - matlab file\n",
    "  Output: patient_list - set of patient IDs\n",
    "  \"\"\"\n",
    "  patient_list = []\n",
    "  for line in mat_file['image_data'][0]:\n",
    "    patient_list.append(line[0][0])\n",
    "\n",
    "  patient_list = set(patient_list)\n",
    "\n",
    "  return patient_list\n",
    "\n",
    "\n",
    "def map_patient_to_img_technique(mat_file, patient_list):\n",
    "  \"\"\"\n",
    "  Input: mat_file - matlab file\n",
    "         patient_list - set or list of patients\n",
    "  Output: patient_img_technique_map - dict of patients with their MRI image type\n",
    "  \"\"\"\n",
    "  patient_img_technique_map = {}\n",
    "\n",
    "  for patient_id in patient_list:\n",
    "    img_techniques = []\n",
    "    for line in mat_file['image_data'][0]:\n",
    "      if line[0][0] == patient_id and line[3][0] not in img_techniques:\n",
    "        img_techniques.append(line[3][0])\n",
    "    patient_img_technique_map[patient_id] = img_techniques\n",
    "\n",
    "  return patient_img_technique_map\n",
    "\n",
    "\n",
    "def rescale_img(img_array, resolution):\n",
    "  \"\"\"\n",
    "  Input: img_array - 2D numpy image array\n",
    "         resolution - tuple of (height, width)\n",
    "  Output: res - rescaled 2D numpy image array\n",
    "  \"\"\"\n",
    "  if img_array.shape != resolution:\n",
    "    res = cv2.resize(img_array, dsize=resolution, interpolation=cv2.INTER_CUBIC)\n",
    "  else:\n",
    "    res = img_array\n",
    "  return res\n",
    "\n",
    "\n",
    "def stack_mri_slices(img_slices):\n",
    "  \"\"\"\n",
    "  Input: img_slices - numpy array of images to stack\n",
    "\n",
    "  Output: img_3D - stacked MRI images\n",
    "  \"\"\"\n",
    "  img_3D = np.dstack(img_slices)\n",
    "  img_3D = img_3D[:, :, :, np.newaxis]\n",
    "  return img_3D\n",
    "\n",
    "# print(df_loaded['Technique'].value_counts())\n",
    "\n",
    "# rescale images to desired resolution\n",
    "TARGET_RESOLUTION = (INPUT_RESOLUTION[0], INPUT_RESOLUTION[1])\n",
    "for idx in df_loaded.index:\n",
    "  try:\n",
    "    df_loaded['Data'][idx] = rescale_img(df_loaded['Data'][idx], TARGET_RESOLUTION)\n",
    "    # print(df_loaded['Data'][idx].shape)\n",
    "  except:\n",
    "    print('failed at: ', idx)\n",
    "\n",
    "# get list of patients and shuffle\n",
    "patient_list = df_loaded['Patient_ID'].unique() # get a list of patients\n",
    "# print(patient_list)\n",
    "patient_list = np.delete(patient_list, 58)      # remove a patient ID\n",
    "patient_list = np.delete(patient_list, np.where(patient_list == '02445263'))\n",
    "patient_list = np.delete(patient_list, np.where(patient_list == '15816944'))\n",
    "# print(len(patient_list))\n",
    "# print(patient_list)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(patient_list)                 # shuffle the patient list\n",
    "# print(patient_list)\n",
    "\n",
    "train_patients = patient_list[0:46]   # 70% of patients for training\n",
    "# print(train_patients)\n",
    "test_patients = patient_list[46:]     # 30% of patients for testing\n",
    "# print(test_patients)\n",
    "\n",
    "# build training/testing dataset\n",
    "\n",
    "x_data_train_dict = {}\n",
    "y_data_train_dict = {}\n",
    "x_data_test_dict = {}\n",
    "y_data_test_dict = {}\n",
    "x_data_all_dict = {}\n",
    "y_data_all_dict = {}\n",
    "\n",
    "num_slices = INPUT_RESOLUTION[2]\n",
    "\n",
    "# TRAINING data x\n",
    "for patient_id in train_patients:\n",
    "  try:\n",
    "    patient_df = df_loaded.loc[df_loaded['Patient_ID'] == patient_id]\n",
    "    patient_mri_data = patient_df.loc[patient_df['Technique'] == 'SWAN']\n",
    "    num_mri_slices = patient_mri_data['Data'].shape[0]\n",
    "    # print(num_mri_slices)\n",
    "\n",
    "    start_idx = int(num_mri_slices/2) - 32\n",
    "    end_idx = int(num_mri_slices/2) +32\n",
    "    print('start: ', start_idx, 'end: ', end_idx)\n",
    "\n",
    "    if CENTERING:\n",
    "      patient_mri_data = stack_mri_slices(patient_mri_data['Data'].to_numpy()[start_idx:end_idx])\n",
    "      # print(patient_mri_data.shape)\n",
    "    else:\n",
    "      patient_mri_data = stack_mri_slices(patient_mri_data['Data'].to_numpy()[0:num_slices])\n",
    "      # print(patient_mri_data.shape)\n",
    "    x_data_train_dict[patient_id] = patient_mri_data\n",
    "\n",
    "  except:\n",
    "    print('no data: ', patient_id)\n",
    "    patient_df = df_loaded.loc[df_loaded['Patient_ID'] == patient_id]\n",
    "    patient_mri_data = patient_df.loc[patient_df['Technique'] == 'Ax DWI Asset']\n",
    "    num_mri_slices = patient_mri_data['Data'].shape[0]\n",
    "    # print(num_mri_slices)\n",
    "\n",
    "    start_idx = int(num_mri_slices/2) - 32\n",
    "    end_idx = int(num_mri_slices/2) + 32\n",
    "    print('start: ', start_idx, 'end: ', end_idx)\n",
    "\n",
    "    if CENTERING:\n",
    "      patient_mri_data = stack_mri_slices(patient_mri_data['Data'].to_numpy()[start_idx:end_idx])\n",
    "      # print(patient_mri_data.shape)\n",
    "    else:\n",
    "      patient_mri_data = stack_mri_slices(patient_mri_data['Data'].to_numpy()[0:num_slices])\n",
    "      # print(patient_mri_data.shape)      \n",
    "    x_data_train_dict[patient_id] = patient_mri_data\n",
    "\n",
    "# print(len(x_data_train_dict))\n",
    "# print(x_data_train_dict)\n",
    "\n",
    "# TRAINING data y\n",
    "for patient_id in train_patients:\n",
    "  outcome = df_loaded.loc[df_loaded['Patient_ID'] == patient_id, 'Designator'].iloc[0]\n",
    "  if outcome == 'responsive':\n",
    "    y_data_train_dict[patient_id] = 1\n",
    "  elif outcome == 'unresponsive':\n",
    "    y_data_train_dict[patient_id] = 0\n",
    "\n",
    "# print(len(y_data_train_dict))\n",
    "# print(y_data_train_dict)\n",
    "\n",
    "# TESTING data x\n",
    "# print(len(test_patients))\n",
    "for patient_id in test_patients:\n",
    "  # print(patient_id)\n",
    "  try:\n",
    "    patient_df = df_loaded.loc[df_loaded['Patient_ID'] == patient_id]\n",
    "    patient_mri_data = patient_df.loc[patient_df['Technique'] == 'SWAN']\n",
    "    num_mri_slices = patient_mri_data['Data'].shape[0]\n",
    "    # print(num_mri_slices)\n",
    "\n",
    "    start_idx = int(num_mri_slices/2) - 32\n",
    "    end_idx = int(num_mri_slices/2) +32\n",
    "    print('start: ', start_idx, 'end: ', end_idx)\n",
    "\n",
    "    if CENTERING:\n",
    "      patient_mri_data = stack_mri_slices(patient_mri_data['Data'].to_numpy()[start_idx:end_idx])\n",
    "      # print(patient_mri_data.shape)\n",
    "    else:\n",
    "      patient_mri_data = stack_mri_slices(patient_mri_data['Data'].to_numpy()[0:num_slices])\n",
    "      # print(patient_mri_data.shape)    \n",
    "    x_data_test_dict[patient_id] = patient_mri_data\n",
    "\n",
    "  except:\n",
    "    # print('no data: ', patient_id)\n",
    "    patient_df = df_loaded.loc[df_loaded['Patient_ID'] == patient_id]\n",
    "    patient_mri_data = patient_df.loc[patient_df['Technique'] == 'Ax DWI Asset']\n",
    "    num_mri_slices = patient_mri_data['Data'].shape[0]\n",
    "    # print(num_mri_slices)\n",
    "\n",
    "    start_idx = int(num_mri_slices/2) - 32\n",
    "    end_idx = int(num_mri_slices/2) +32\n",
    "    print('start: ', start_idx, 'end: ', end_idx)\n",
    "\n",
    "    if CENTERING:    \n",
    "      patient_mri_data = stack_mri_slices(patient_mri_data['Data'].to_numpy()[start_idx:end_idx])\n",
    "      # print(patient_mri_data.shape)\n",
    "    else:\n",
    "      patient_mri_data = stack_mri_slices(patient_mri_data['Data'].to_numpy()[0:num_slices])\n",
    "      # print(patient_mri_data.shape)    \n",
    "    x_data_test_dict[patient_id] = patient_mri_data\n",
    "\n",
    "# print(len(x_data_test_dict))\n",
    "# print(x_data_test_dict)\n",
    "\n",
    "\n",
    "# TESTING data y\n",
    "for patient_id in test_patients:\n",
    "  outcome = df_loaded.loc[df_loaded['Patient_ID'] == patient_id, 'Designator'].iloc[0]\n",
    "  if outcome == 'responsive':\n",
    "    y_data_test_dict[patient_id] = 1\n",
    "  elif outcome == 'unresponsive':\n",
    "    y_data_test_dict[patient_id] = 0\n",
    "\n",
    "#print(len(y_data_test_dict))\n",
    "# print(y_data_train_dict)\n",
    "\n",
    "# print(patient_mri_data.shape)\n",
    "# print(patient_df['Technique'].value_counts())\n",
    "\n",
    "#print('x data train shape:')\n",
    "#for patient in x_data_train_dict:\n",
    "#  print(x_data_train_dict[patient].shape)\n",
    "\n",
    "#print('x data test shape:')\n",
    "#for patient in x_data_test_dict:\n",
    "#  print(x_data_test_dict[patient].shape)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for patient_id in train_patients:\n",
    "  x_train.append(x_data_train_dict[patient_id])\n",
    "  y_train.append(y_data_train_dict[patient_id])\n",
    "\n",
    "for patient_id in test_patients:\n",
    "  x_test.append(x_data_test_dict[patient_id])\n",
    "  y_test.append(y_data_test_dict[patient_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data into Pytorch Data Structures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "print(x_train.shape)\n",
    "x_train_T = x_train.transpose(0, 4, 3, 1, 2)\n",
    "print(x_train_T.shape)\n",
    "y_train = np.asarray(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = np.asarray(x_test)\n",
    "print(x_test.shape)\n",
    "x_test_T = x_test.transpose(0, 4, 3, 1, 2)\n",
    "print(x_test_T.shape)\n",
    "y_test = np.asarray(y_test)\n",
    "print(y_test.shape)\n",
    "\n",
    "tensor_x_train = torch.Tensor(x_train_T).to(device)\n",
    "# print(tensor_x_train)\n",
    "tensor_y_train = torch.Tensor(y_train).to(device)\n",
    "tensor_y_train = tensor_y_train.type(torch.long)\n",
    "# print(tensor_y_train)\n",
    "train_dataset = TensorDataset(tensor_x_train, tensor_y_train)\n",
    "# print(train_dataset.tensors)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "\n",
    "tensor_x_test = torch.Tensor(x_test_T).to(device)\n",
    "# print(tensor_x_test)\n",
    "tensor_y_test = torch.Tensor(y_test).to(device)\n",
    "tensor_y_test = tensor_y_test.type(torch.long)\n",
    "# print(tensor_y_test)\n",
    "test_dataset = TensorDataset(tensor_x_test, tensor_y_test)\n",
    "# print(test_dataset.tensors)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "\n",
    "print('Training set has {} instances'.format(len(train_dataset)))\n",
    "print('Validation set has {} instances'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define 3-D Vision Transformer Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_model = ViT(\n",
    "                image_size = INPUT_RESOLUTION[0],          # image size\n",
    "                frames = INPUT_RESOLUTION[2],              # number of frames\n",
    "                image_patch_size = 16,                     # image patch size\n",
    "                frame_patch_size = 4,                      # frame patch size\n",
    "                num_classes = 2,\n",
    "                dim = 1024,\n",
    "                depth = 6,\n",
    "                heads = 8,\n",
    "                mlp_dim = 2048,\n",
    "                dropout = 0.1,\n",
    "                emb_dropout = 0.1,\n",
    "                channels=1\n",
    "                ).to(device)\n",
    "\n",
    "summary(model=vit_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "N_EPOCHS = 50\n",
    "LR = 0.005\n",
    "\n",
    "losses = []\n",
    "accuracy_vals = []\n",
    "\n",
    "optimizer = Adam(vit_model.parameters(), lr=LR)\n",
    "criterion = CrossEntropyLoss().to(device)\n",
    "for epoch in trange(N_EPOCHS, desc=\"Training\"):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_accuracy = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
    "        x, y = batch\n",
    "        x, y = x, y\n",
    "        y_hat = vit_model(x).to(device)\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        epoch_loss += loss.detach().cpu().item() / len(train_loader)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "        epoch_accuracy += acc.cpu() / len(train_loader)\n",
    "\n",
    "    losses.append(epoch_loss)\n",
    "    accuracy_vals.append(epoch_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {epoch_loss:.2f}, accuracy: {epoch_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy/loss\n",
    "print('accuracy vals: {}', accuracy_vals)\n",
    "print('loss vals: {}', losses)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(accuracy_vals)\n",
    "plt.ylim([0, 1])\n",
    "plt.title('MRI model accuracy, 3-D ViT')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(losses)\n",
    "plt.ylim([0, 1])\n",
    "plt.title('MRI model loss, 3-D ViT')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct, total = 0, 0\n",
    "    test_loss = 0.0\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = vit_model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        test_loss += loss.detach().cpu().item() / len(test_loader)\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "    print(f\"Test loss: {test_loss:.2f}\")\n",
    "    print(f\"Test accuracy: {correct / total * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
