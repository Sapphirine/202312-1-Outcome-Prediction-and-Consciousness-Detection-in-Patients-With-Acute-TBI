{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4hndsrNpXTY"
   },
   "source": [
    "# **Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Vars\n",
    "GENERATE_MATLAB_DATA = False\n",
    "DATA_PATH = '/home/cyu/workspace/202312-1-Outcome-Prediction-and-Consciousness-Detection-in-Patients-With-Acute-TBI/data/mri_data_pandas.pkl'\n",
    "RESULT_PATH = '/home/cyu/workspace/202312-1-Outcome-Prediction-and-Consciousness-Detection-in-Patients-With-Acute-TBI/data/MRI_Model.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyGZ5wm8pbL2"
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Input, Conv3D, MaxPooling3D, Flatten, Dense, GlobalAveragePooling3D, add, BatchNormalization, Activation, Dropout\n",
    "from keras.models import Model\n",
    "import keras\n",
    "import scipy.io\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# List available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(\"GPU Available:\", gpu)\n",
    "else:\n",
    "    print(\"No GPU devices found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQu-a0nFpM1q"
   },
   "source": [
    "# **Load MRI Data from Matlab file (run once if data didn't change)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7AWwbYmPUd5"
   },
   "outputs": [],
   "source": [
    "# Read in Matlab data\n",
    "if GENERATE_MATLAB_DATA:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "\n",
    "  matlab_datasets = []\n",
    "\n",
    "  for i in range(1, 17):\n",
    "    try:\n",
    "      mat = scipy.io.loadmat('/content/drive/MyDrive/Fall 2023/EECS E6893 - Big Data Analytics/Final_Project/MRI Matlab Data/image_data{num}.mat'.format(num = i))\n",
    "      matlab_datasets.append(mat)\n",
    "    except:\n",
    "      continue\n",
    "\n",
    "  # print(len(matlab_datasets))\n",
    "\n",
    "  patient_ids = []\n",
    "  designators = []\n",
    "  imaging_types = []\n",
    "  techniques = []\n",
    "  datasets = []\n",
    "\n",
    "  # create a Pandas dataframe\n",
    "  for matfile in matlab_datasets:\n",
    "\n",
    "    try:\n",
    "      for line in matfile['image_data'][0]:\n",
    "        patient_ids.append(line[0][0])\n",
    "        designators.append(line[1][0])\n",
    "        imaging_types.append(line[2][0])\n",
    "        techniques.append(line[3][0])\n",
    "        datasets.append(line[4])\n",
    "    except:\n",
    "      print('line issue: ', line[5][0])\n",
    "\n",
    "  data = {\n",
    "      \"Patient_ID\": patient_ids,\n",
    "      \"Designator\": designators,\n",
    "      \"Imaging_Type\": imaging_types,\n",
    "      \"Technique\": techniques,\n",
    "      \"Data\": datasets,\n",
    "  }\n",
    "\n",
    "  df = pd.DataFrame(data)\n",
    "  # print(df)\n",
    "\n",
    "  # save Pandas dataframe\n",
    "  df.to_pickle(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7edfeLVxTzI8"
   },
   "source": [
    "# **Load MRI Data from Pandas DF (start here)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzw-bB2zRvEG"
   },
   "outputs": [],
   "source": [
    "# load Pandas dataframe\n",
    "if GENERATE_MATLAB_DATA:\n",
    "    drive.mount('/content/drive')\n",
    "file_name = DATA_PATH\n",
    "df_loaded = pd.read_pickle(file_name)\n",
    "# print(df_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltRMPNSiUZUc"
   },
   "source": [
    "# **Organize Data for Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-oYU8-hY0e3"
   },
   "outputs": [],
   "source": [
    "def get_patient_list(mat_file):\n",
    "  \"\"\"\n",
    "  Input: mat_file - matlab file\n",
    "  Output: patient_list - set of patient IDs\n",
    "  \"\"\"\n",
    "  patient_list = []\n",
    "  for line in mat_file['image_data'][0]:\n",
    "    patient_list.append(line[0][0])\n",
    "\n",
    "  patient_list = set(patient_list)\n",
    "\n",
    "  return patient_list\n",
    "\n",
    "\n",
    "def map_patient_to_img_technique(mat_file, patient_list):\n",
    "  \"\"\"\n",
    "  Input: mat_file - matlab file\n",
    "         patient_list - set or list of patients\n",
    "  Output: patient_img_technique_map - dict of patients with their MRI image type\n",
    "  \"\"\"\n",
    "  patient_img_technique_map = {}\n",
    "\n",
    "  for patient_id in patient_list:\n",
    "    img_techniques = []\n",
    "    for line in mat_file['image_data'][0]:\n",
    "      if line[0][0] == patient_id and line[3][0] not in img_techniques:\n",
    "        img_techniques.append(line[3][0])\n",
    "    patient_img_technique_map[patient_id] = img_techniques\n",
    "\n",
    "  return patient_img_technique_map\n",
    "\n",
    "\n",
    "def rescale_img(img_array, resolution):\n",
    "  \"\"\"\n",
    "  Input: img_array - 2D numpy image array\n",
    "         resolution - tuple of (height, width)\n",
    "  Output: res - rescaled 2D numpy image array\n",
    "  \"\"\"\n",
    "  if img_array.shape != resolution:\n",
    "    res = cv2.resize(img_array, dsize=resolution, interpolation=cv2.INTER_CUBIC)\n",
    "  else:\n",
    "    res = img_array\n",
    "  return res\n",
    "\n",
    "\n",
    "def stack_mri_slices(img_slices):\n",
    "  \"\"\"\n",
    "\n",
    "  \"\"\"\n",
    "  img_3D = np.dstack(img_slices)\n",
    "  img_3D = img_3D[:, :, :, np.newaxis]\n",
    "  return img_3D\n",
    "\n",
    "# print(df_loaded['Technique'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rp6fd1U9QJcx"
   },
   "outputs": [],
   "source": [
    "# rescale images to desired resolution\n",
    "TARGET_RESOLUTION = (256, 256)\n",
    "for idx in df_loaded.index:\n",
    "  try:\n",
    "    df_loaded['Data'][idx] = rescale_img(df_loaded['Data'][idx], TARGET_RESOLUTION)\n",
    "    # print(df_loaded['Data'][idx].shape)\n",
    "  except:\n",
    "    print('failed at: ', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AFvmOmoQLVn"
   },
   "outputs": [],
   "source": [
    "# get list of patients and shuffle\n",
    "\n",
    "patient_list = df_loaded['Patient_ID'].unique() # get a list of patients\n",
    "# print(patient_list)\n",
    "patient_list = np.delete(patient_list, 58)      # remove a patient ID\n",
    "patient_list = np.delete(patient_list, np.where(patient_list == '02445263'))\n",
    "patient_list = np.delete(patient_list, np.where(patient_list == '15816944'))\n",
    "# print(len(patient_list))\n",
    "# print(patient_list)\n",
    "np.random.shuffle(patient_list)                 # shuffle the patient list\n",
    "# print(patient_list)\n",
    "\n",
    "train_patients = patient_list[0:46]   # 70% of patients for training\n",
    "# print(train_patients)\n",
    "test_patients = patient_list[46:]     # 30% of patients for testing\n",
    "# print(test_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HD4XrNeYguRh"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_loaded.loc[df_loaded['Patient_ID'] == '15816944', 'Technique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgCB3mN9f3ZS"
   },
   "outputs": [],
   "source": [
    "# build training/testing dataset\n",
    "\n",
    "x_data_train_dict = {}\n",
    "y_data_train_dict = {}\n",
    "x_data_test_dict = {}\n",
    "y_data_test_dict = {}\n",
    "x_data_all_dict = {}\n",
    "y_data_all_dict = {}\n",
    "\n",
    "num_slices = 64\n",
    "\n",
    "# TRAINING data x\n",
    "for patient_id in train_patients:\n",
    "  try:\n",
    "    patient_df = df_loaded.loc[df_loaded['Patient_ID'] == patient_id]\n",
    "    patient_mri_data = patient_df.loc[patient_df['Technique'] == 'SWAN']\n",
    "    num_mri_slices = patient_mri_data['Data'].shape[0]\n",
    "    # print(num_mri_slices)\n",
    "\n",
    "    start_idx = int(num_mri_slices/2) - 32\n",
    "    end_idx = int(num_mri_slices/2) +32\n",
    "    print('start: ', start_idx, 'end: ', end_idx)\n",
    "\n",
    "    patient_mri_data = stack_mri_slices(patient_mri_data['Data'].to_numpy()[start_idx:end_idx])\n",
    "    # print(patient_mri_data.shape)\n",
    "    x_data_train_dict[patient_id] = patient_mri_data\n",
    "\n",
    "  except:\n",
    "    print('no data: ', patient_id)\n",
    "    patient_df = df_loaded.loc[df_loaded['Patient_ID'] == patient_id]\n",
    "    patient_mri_data = patient_df.loc[patient_df['Technique'] == 'Ax DWI Asset']\n",
    "    num_mri_slices = patient_mri_data['Data'].shape[0]\n",
    "    # print(num_mri_slices)\n",
    "\n",
    "    start_idx = int(num_mri_slices/2) - 32\n",
    "    end_idx = int(num_mri_slices/2) + 32\n",
    "    print('start: ', start_idx, 'end: ', end_idx)\n",
    "\n",
    "    patient_mri_data = stack_mri_slices(patient_mri_data['Data'].to_numpy()[start_idx:end_idx])\n",
    "    # print(patient_mri_data.shape)\n",
    "    x_data_train_dict[patient_id] = patient_mri_data\n",
    "\n",
    "# print(len(x_data_train_dict))\n",
    "# print(x_data_train_dict)\n",
    "\n",
    "# TRAINING data y\n",
    "for patient_id in train_patients:\n",
    "  outcome = df_loaded.loc[df_loaded['Patient_ID'] == patient_id, 'Designator'].iloc[0]\n",
    "  if outcome == 'responsive':\n",
    "    y_data_train_dict[patient_id] = 1\n",
    "  elif outcome == 'unresponsive':\n",
    "    y_data_train_dict[patient_id] = 0\n",
    "\n",
    "# print(len(y_data_train_dict))\n",
    "# print(y_data_train_dict)\n",
    "\n",
    "# TESTING data x\n",
    "# print(len(test_patients))\n",
    "for patient_id in test_patients:\n",
    "  # print(patient_id)\n",
    "  try:\n",
    "    patient_df = df_loaded.loc[df_loaded['Patient_ID'] == patient_id]\n",
    "    patient_mri_data = patient_df.loc[patient_df['Technique'] == 'SWAN']\n",
    "    num_mri_slices = patient_mri_data['Data'].shape[0]\n",
    "    # print(num_mri_slices)\n",
    "\n",
    "    start_idx = int(num_mri_slices/2) - 32\n",
    "    end_idx = int(num_mri_slices/2) +32\n",
    "    print('start: ', start_idx, 'end: ', end_idx)\n",
    "\n",
    "    patient_mri_data = stack_mri_slices(patient_mri_data['Data'].to_numpy()[start_idx:end_idx])\n",
    "\n",
    "    # print(patient_mri_data.shape)\n",
    "    x_data_test_dict[patient_id] = patient_mri_data\n",
    "\n",
    "  except:\n",
    "    # print('no data: ', patient_id)\n",
    "    patient_df = df_loaded.loc[df_loaded['Patient_ID'] == patient_id]\n",
    "    patient_mri_data = patient_df.loc[patient_df['Technique'] == 'Ax DWI Asset']\n",
    "    num_mri_slices = patient_mri_data['Data'].shape[0]\n",
    "    # print(num_mri_slices)\n",
    "\n",
    "    start_idx = int(num_mri_slices/2) - 32\n",
    "    end_idx = int(num_mri_slices/2) +32\n",
    "    print('start: ', start_idx, 'end: ', end_idx)\n",
    "\n",
    "    patient_mri_data = stack_mri_slices(patient_mri_data['Data'].to_numpy()[start_idx:end_idx])\n",
    "    # print(patient_mri_data.shape)\n",
    "    x_data_test_dict[patient_id] = patient_mri_data\n",
    "\n",
    "# print(len(x_data_test_dict))\n",
    "# print(x_data_test_dict)\n",
    "\n",
    "\n",
    "# TESTING data y\n",
    "for patient_id in test_patients:\n",
    "  outcome = df_loaded.loc[df_loaded['Patient_ID'] == patient_id, 'Designator'].iloc[0]\n",
    "  if outcome == 'responsive':\n",
    "    y_data_test_dict[patient_id] = 1\n",
    "  elif outcome == 'unresponsive':\n",
    "    y_data_test_dict[patient_id] = 0\n",
    "\n",
    "#print(len(y_data_test_dict))\n",
    "# print(y_data_train_dict)\n",
    "\n",
    "# print(patient_mri_data.shape)\n",
    "# print(patient_df['Technique'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUiwW4XxZ-sl"
   },
   "outputs": [],
   "source": [
    "#print('x data train shape:')\n",
    "#for patient in x_data_train_dict:\n",
    "#  print(x_data_train_dict[patient].shape)\n",
    "\n",
    "#print('x data test shape:')\n",
    "#for patient in x_data_test_dict:\n",
    "#  print(x_data_test_dict[patient].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PtpLL7e8ryLE"
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for patient_id in train_patients:\n",
    "  x_train.append(x_data_train_dict[patient_id])\n",
    "  y_train.append(y_data_train_dict[patient_id])\n",
    "\n",
    "for patient_id in test_patients:\n",
    "  x_test.append(x_data_test_dict[patient_id])\n",
    "  y_test.append(y_data_test_dict[patient_id])\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "print(x_train.shape)\n",
    "y_train = np.asarray(y_train)\n",
    "# print(y_train.shape)\n",
    "x_test = np.asarray(x_test)\n",
    "# print(x_test.shape)\n",
    "y_test = np.asarray(y_test)\n",
    "# print(y_test.shape)\n",
    "\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "\n",
    "batch_size = 1\n",
    "# Augment the on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "    # .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "\n",
    "test_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "batch_size = 1\n",
    "# Augment the on the fly during training.\n",
    "test_dataset = (\n",
    "    test_loader.shuffle(len(x_test))\n",
    "    # .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsJITyYlKMBp"
   },
   "source": [
    "# 3D Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpV2q7M1Kba3"
   },
   "outputs": [],
   "source": [
    "def get_model(width=128, height=128, depth=64):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = Input((width, height, depth, 1))\n",
    "\n",
    "    x = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # x = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    # x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = GlobalAveragePooling3D()(x)\n",
    "    x = Dense(units=512, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    outputs = Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "# Build model.\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "DEPTH = 64\n",
    "model = get_model(width=WIDTH, height=HEIGHT, depth=DEPTH)\n",
    "model.summary()\n",
    "\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "train_out = model.fit(train_dataset, validation_data=test_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wlsQUpynsxL"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dx91ajK-zRyA"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(train_out.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(train_out.history['acc'])\n",
    "plt.plot(train_out.history['val_acc'])\n",
    "plt.ylim([0, 1])\n",
    "plt.title('MRI model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(train_out.history['loss'])\n",
    "plt.plot(train_out.history['val_loss'])\n",
    "plt.ylim([0, 1])\n",
    "plt.title('MRI model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfxD51JOhWUf"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "loaded_model = keras.saving.load_model(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SQ1TwREZ4E1"
   },
   "outputs": [],
   "source": [
    "model.predict(test_dataset.take(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjL9wpfVve1K"
   },
   "outputs": [],
   "source": [
    "x_data_all_dict = {**x_data_train_dict, **x_data_test_dict}\n",
    "y_data_all_dict = {**y_data_train_dict, **y_data_test_dict}\n",
    "\n",
    "print('label:', y_data_all_dict['00123691'])\n",
    "\n",
    "eval_data = x_data_all_dict['00123691']\n",
    "eval_data = eval_data[None, :]\n",
    "print(eval_data.shape)\n",
    "eval_loader = tf.data.Dataset.from_tensors(eval_data)\n",
    "\n",
    "loaded_model.predict(eval_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
